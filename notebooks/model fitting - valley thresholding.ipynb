{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting: solving gene trascription state classification with _ShallowChrome_ and 'valley' thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model as lm\n",
    "import os\n",
    "import matplotlib\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths\n",
    "\n",
    "root_path = './../'\n",
    "\n",
    "# path to data, random splits, cell list\n",
    "data_base_path = root_path+'data/'\n",
    "split_base_path = data_base_path+'- splits/'\n",
    "cell_list_path = data_base_path+'cells.csv'\n",
    "\n",
    "# path to folder where to write results\n",
    "score_base_path = root_path+'scores/'\n",
    "try:\n",
    "    os.mkdir(score_base_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# suffixes\n",
    "data_suffix = 'stripped/'\n",
    "X_tail = 'X.csv'\n",
    "T_tail = 'T.csv'\n",
    "deepchrome_suffix = 'DeepChrome_scores.txt'\n",
    "\n",
    "# prepare list of data folders where to read\n",
    "# so to feed all the considered combinations\n",
    "# of input formats\n",
    "formats = ['- broad', '- broad narrow', '- gapped', '- gapped broad', '- gapped narrow', '- narrow']\n",
    "folders_by_format = list()\n",
    "for form in formats:\n",
    "    base = data_base_path + form + '/'\n",
    "    folders, cells = load_cell_paths(cell_list_path, base, suffix='/'+data_suffix)\n",
    "    folders_by_format.append(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set target epigenomes, model and fitting paramerters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will train and evaluate _ShallowChrome_ across all 56 epigenomes. Specific epigenomes of interest can be specified via variable `target_cells`. For example, one may just specify epigenomes `target_cells = ['E003', 'E123', 'E116']`, those for which pattern analyses are made in notebook `model inspection`.\n",
    "\n",
    "NB: l2-penalty coefficient `C = +∞` effectively enforces no penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target epigenome(s)\n",
    "\n",
    "# target_cells = ['E003', 'E123', 'E116']\n",
    "target_cells = cells\n",
    "cs = [np.where(cells==cell)[0][0] for cell in target_cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model and fitting parameters\n",
    "\n",
    "penalty='l2'\n",
    "C = + np.inf\n",
    "solver = 'lbfgs'\n",
    "max_iter = 6000\n",
    "multi_class = 'multinomial'\n",
    "random_state = 666\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 'valley' binary thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute binary thresholds with both the 'median' and 'valley' approach and compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture out\n",
    "\n",
    "diffs = list()\n",
    "medians = list()\n",
    "threshs = list()\n",
    "\n",
    "for c, cell in zip(cs, target_cells):\n",
    "\n",
    "    # print advancement message\n",
    "    print '\\r>> cell {0}...'.format(cell),\n",
    "    \n",
    "    # retrieve data\n",
    "    folder = folders_by_format[0][c]\n",
    "    X = np.loadtxt(folder+X_tail, delimiter=',')\n",
    "    T_raw = np.loadtxt(folder+T_tail, delimiter=',')\n",
    "\n",
    "    # perform binarization based\n",
    "    # on valley thresholding\n",
    "    T_tr = np.log(1 + T_raw)\n",
    "    freqs, edges, _ = plt.hist(T_tr, bins=100, color='cadetblue') \n",
    "    thresh = np.exp(find_valley(T_tr, freqs, edges)) - 1\n",
    "    median = np.median(T_raw)\n",
    "    diff = median - thresh\n",
    "    medians.append(median)\n",
    "    threshs.append(thresh)\n",
    "    diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show the distribution with largest gap\n",
    "\n",
    "# retrieve data\n",
    "largest = np.argmax(diffs)\n",
    "name = \"Set2\"\n",
    "cmap = matplotlib.cm.get_cmap(name)\n",
    "colors = cmap.colors\n",
    "folder = folders_by_format[0][largest]\n",
    "T_raw = np.loadtxt(folder+T_tail, delimiter=',')\n",
    "\n",
    "# perform binarization based\n",
    "# on valley thresholding\n",
    "T_tr = np.log(1 + T_raw)\n",
    "fig = plt.figure(dpi=300)\n",
    "plt.hist(T_tr, bins=100, color='cadetblue') \n",
    "plt.axvline(x=np.log(1 + np.asarray(medians[largest])), color=colors[1], linewidth=1, label='median threshold')\n",
    "plt.axvline(x=np.log(1 + np.asarray(threshs[largest])), color=colors[2], linewidth=1, label='valley threshold')\n",
    "plt.xticks([np.log(1+threshs[largest]), np.log(1+medians[largest])], ['{:.3f}'.format(t) for t in [threshs[largest], medians[largest]]], fontsize=10)\n",
    "plt.xlabel('RPKMs (log scale)', fontsize=10)\n",
    "plt.ylabel('Bin frequency', fontsize=10)\n",
    "plt.xlim([-0.2,6])\n",
    "plt.title('Epigenome '+cells[largest])\n",
    "plt.legend(fontsize=10)\n",
    "fig.tight_layout()\n",
    "plt.savefig('./valley.pdf', format='pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train _ShallowChrome_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train, select and evaluate _ShallowChrome_ models for each target epigenome. In order to get some statistical confidence on model performance, the procedure is repeated `iterations` times; each time a different, randomly generated dataset split is employed.\n",
    "\n",
    "NB: The use of a threshold different than the median causes the two classes to be unbalanced. Here we simply adopt a subsampling strategy to guarantee balanced training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training!\n",
    "    \n",
    "val_scores_by_cell = dict()\n",
    "test_scores_by_cell = dict()\n",
    "for c, cell in zip(cs, target_cells):\n",
    "    \n",
    "    # print advancement message\n",
    "    print '\\n\\n>> cell {0}...'.format(cell)\n",
    "\n",
    "    # set score folder(s)\n",
    "    score_folder = score_base_path+str(cell)\n",
    "    try:\n",
    "        os.mkdir(score_folder)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    # define score matrices\n",
    "    S_val = np.ndarray((len(formats), iterations))\n",
    "    S_test = np.ndarray((len(formats), iterations))\n",
    "\n",
    "    # loop for data formats\n",
    "    for f, form in enumerate(formats):\n",
    "\n",
    "        # set score folder for format\n",
    "        score_folder_format = score_folder+'/'+form+'/'\n",
    "        try:\n",
    "            os.mkdir(score_folder_format)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "        # retrieve data\n",
    "        folder = folders_by_format[f][c]\n",
    "        X = np.loadtxt(folder+X_tail, delimiter=',')\n",
    "        T_raw = np.loadtxt(folder+T_tail, delimiter=',')\n",
    "        \n",
    "        # perform binarization based\n",
    "        # on valley thresholding\n",
    "        thresh = threshs[c]\n",
    "        T = binarize_target(T_raw, thresh)\n",
    "        \n",
    "        # re-balance by subsampling and\n",
    "        # recompute random split\n",
    "        X_v, T_v = balance_by_subsampling(X, T, random_state=random_state)\n",
    "        splits = random_splits(len(T_v), iterations=iterations, random_state=random_state)\n",
    "        \n",
    "        # monitoring\n",
    "        if f == 0:\n",
    "            print '\\n\\tthreshold for epigenome {} is {:.3f} (was {:.3f})'.format(cell, thresh, np.median(T_raw))\n",
    "            print '\\tnew dataset length is {}'.format(len(T_v))\n",
    "\n",
    "        # print advancement message\n",
    "        print '\\r\\tformat: {0}        '.format(form),\n",
    "\n",
    "        # loop over random splits\n",
    "        for i in range(iterations): \n",
    "\n",
    "            # instantiate model\n",
    "            model = lm.LogisticRegression(penalty=penalty, C=C, random_state=random_state, solver=solver, max_iter=max_iter, multi_class=multi_class)\n",
    "            \n",
    "            # get split\n",
    "            split = splits[i]\n",
    "\n",
    "            # fit model\n",
    "            cache_model_at = score_folder_format+'model_C_'+str(C)+'_iter_'+str(i+1)+'.pkl'\n",
    "            S_val[f,i], S_test[f,i] = fit_and_score(model, X, T, split, cache_model_at)\n",
    "\n",
    "    # save scores to disk\n",
    "    np.savetxt(score_folder+'/val_aucs_valley.csv', S_val, delimiter=',', fmt='%.4f')\n",
    "    np.savetxt(score_folder+'/test_aucs_valley.csv', S_test, delimiter=',', fmt='%.4f')\n",
    "    \n",
    "    # store them into dict\n",
    "    val_scores_by_cell[cell] = S_val\n",
    "    test_scores_by_cell[cell] = S_test\n",
    "    \n",
    "print ' done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_scores = dict()\n",
    "final_test_scores = dict()\n",
    "final_selection = dict()\n",
    "\n",
    "for cell in target_cells:\n",
    "    \n",
    "    S_val = val_scores_by_cell[cell]\n",
    "    S_test = test_scores_by_cell[cell]\n",
    "    final_val_scores[cell] = list()\n",
    "    final_test_scores[cell] = list()\n",
    "    final_selection[cell] = list()\n",
    "    for split in range(iterations):\n",
    "\n",
    "        val_scores = S_val[:, split]\n",
    "        test_scores = S_test[:, split]\n",
    "        best = np.argmax(val_scores)\n",
    "\n",
    "        final_val_scores[cell].append(val_scores[best])\n",
    "        final_test_scores[cell].append(test_scores[best])\n",
    "        final_selection[cell].append(formats[best])\n",
    "    \n",
    "    # print test performance\n",
    "    print '>> cell {0}: {1:.2f} ± {2:.2f} %'.format(cell, 100 * np.mean(final_test_scores[cell]), 100 * np.std(final_test_scores[cell]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  print aggregated stats\n",
    "\n",
    "data = [np.mean(final_test_scores[cell]) for cell in target_cells]\n",
    "data_std = [np.std(final_test_scores[cell]) for cell in target_cells]\n",
    "print 'mean:\\t{:.4f}'.format(np.mean(data))\n",
    "print 'median:\\t{:.4f}'.format(np.median(data))\n",
    "print 'max:\\t{:.4f}'.format(np.max(data))\n",
    "print 'min:\\t{:.4f}'.format(np.min(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dump all results\n",
    "\n",
    "shallowchrome_valley_results_path = score_base_path+'ShallowChrome_valley_scores.txt'\n",
    "with open(shallowchrome_valley_results_path, 'w') as score_file:\n",
    "    for c, cell in enumerate(target_cells):\n",
    "        score_file.write(cell+': {0} +/- {1}\\n'.format(data[c], data_std[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare with other methods\n",
    "\n",
    "deepchrome_results_path = score_base_path+deepchrome_suffix\n",
    "deepchrome_scores = parse_scores(deepchrome_results_path, std=False)\n",
    "\n",
    "shallowchrome_results_path = score_base_path+'ShallowChrome_scores.txt'\n",
    "shallowchrome_scores = parse_scores(shallowchrome_results_path, std=True)\n",
    "\n",
    "shallowchrome_valley_scores = parse_scores(shallowchrome_valley_results_path, std=True)\n",
    "\n",
    "target_scores = [deepchrome_scores, shallowchrome_scores, shallowchrome_valley_scores]\n",
    "sorter = np.argsort(-deepchrome_scores[:,0])\n",
    "\n",
    "w = 1.75\n",
    "s = 7\n",
    "y_labels_ = ['DeepChrome', 'ShallowChrome', 'ShallowChrome (valley)']\n",
    "name = \"Set2\"\n",
    "cmap = get_cmap(name)\n",
    "colors = cmap.colors\n",
    "\n",
    "fig = plt.figure(dpi=300, figsize=(10,6))\n",
    "for bb, b in enumerate(target_scores):\n",
    "    scores_mean = b[:,0]\n",
    "    if b.shape[-1] == 2:\n",
    "        std = b[:,1]\n",
    "    else:\n",
    "        std = np.asarray([0]*len(target_cells))\n",
    "    x = s*np.arange(len(target_cells)) + (w * (bb - 0))\n",
    "    plt.bar(x, scores_mean[sorter], width=w, yerr=std[sorter], align='center', ecolor='grey', capsize=0, color=colors[bb], label=y_labels_[bb])\n",
    "plt.yticks(np.arange(0.5, 1.0, 0.05), fontsize=11)\n",
    "plt.xticks(x, target_cells[sorter], fontsize=11, rotation=90)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.xlabel(\"epigenome\", fontsize=14)\n",
    "plt.ylabel(\"AUROC\", fontsize=12)\n",
    "plt.ylim([0.5, 0.93])\n",
    "plt.xlim([x[0]-3*w, x[-1]+w])\n",
    "fig.tight_layout()\n",
    "plt.savefig('./vsValley.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
