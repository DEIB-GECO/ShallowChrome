{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import shutil\n",
    "import gmql as gl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "root_path = './../'\n",
    "data_base_path = root_path + 'data/'\n",
    "raw_data_path = data_base_path + 'raw/'\n",
    "extracted_path = raw_data_path + 'extracted/'\n",
    "if not os.path.exists(raw_data_path):\n",
    "    os.makedirs(extracted_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataframe from Encode for selected Cell lines and Histone Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extimated running time ~150 minutes\n",
    "\n",
    "# load cell_lines\n",
    "with open(data_base_path+'cells.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    cells = list(reader)[0]\n",
    "\n",
    "# load histone_marks\n",
    "with open(data_base_path+'names.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    marks = list(reader)[0]\n",
    "\n",
    "# remote login as \"Guest\" in GMQL    \n",
    "gl.set_mode(\"remote\")\n",
    "gl.set_remote_address(\"http://gmql.eu/gmql-rest/\")\n",
    "gl.login()\n",
    "\n",
    "# load HG19_ROADMAP_EPIGENOMICS dataset from GMQL repository\n",
    "narrow = gl.load_from_remote(\"HG19_ROADMAP_EPIGENOMICS_NARROW\", owner=\"public\")\n",
    "broad = gl.load_from_remote(\"HG19_ROADMAP_EPIGENOMICS_BROAD\", owner=\"public\")\n",
    "gapped = gl.load_from_remote(\"HG19_ROADMAP_EPIGENOMICS_GAPPED\", owner=\"public\")\n",
    "\n",
    "# merge all datasets in one\n",
    "narrow_broad = narrow.union(broad)\n",
    "total = narrow_broad.union(gapped)\n",
    "\n",
    "# filter the dataset for the selected cell lines \n",
    "cell_lines = total[total['epi__epigenome_id'].isin(cells)]\n",
    "\n",
    "# filter the cell_lines for the selected histone marks \n",
    "histone_marks = cell_lines[cell_lines['exp__mark'].isin(marks)]\n",
    "\n",
    "# materialize final results\n",
    "hm = histone_marks.materialize(raw_data_path+\"total_filtered\", all_load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the promoters' file (GeneFile.txt) in GMQL format (GTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Roadmap file\n",
    "genefile = pd.read_csv(data_base_path+\"GeneFile.txt\", sep=\"\\t\", names = [\"seqname\", \"start\", \"end\", \"attribute\"])\n",
    "\n",
    "# set distance from promoter\n",
    "# promoters in file \"GeneFile.txt\" are Â± 10k, resizing is needed\n",
    "genefile.start = genefile.start + 5000\n",
    "genefile.end = genefile.end - 5000\n",
    "\n",
    "# add column to generate a full GTF format file\n",
    "genefile[\"source\"] = \"Roadmap\"\n",
    "genefile[\"feature\"] = \"Gene\"\n",
    "genefile[\"score\"] = \".\"\n",
    "genefile[\"strand\"] = \"+\"\n",
    "genefile[\"frame\"] = \".\"\n",
    "\n",
    "# reorder column\n",
    "genefile = genefile[['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute']]\n",
    "\n",
    "# save gtf file\n",
    "genefile.to_csv(data_base_path+\"GeneFile.gtf\", index=False, sep =\"\\t\", header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersect promoter regions with Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.set_mode(\"local\")\n",
    "\n",
    "# generate custom parser for promoter dataset\n",
    "custom_parser = gl.parsers.RegionParser(chrPos=0, startPos=3, stopPos=4, strandPos=6,\n",
    "                                        otherPos=[(1, \"source\", \"string\"), \n",
    "                                                  (2, \"feature\", \"string\"),\n",
    "                                                  (5, \"score\", \"float\"),\n",
    "                                                  (7, \"frame\", \"string\"),\n",
    "                                                  (8, \"attribute\", \"string\")],\n",
    "                                        coordinate_system='1-based')\n",
    "\n",
    "# import the previously generated promoter dataset in pyGMQL\n",
    "promoter = gl.load_from_file(path=data_base_path+\"GeneFile.gtf\", parser=custom_parser)\n",
    "\n",
    "# find the intersections\n",
    "chip_promoter_0 = promoter.join(experiment=hm,\n",
    "                         genometric_predicate=[gl.DL(0)],\n",
    "                         output='RIGHT')\n",
    "\n",
    "# keep only the needed region and metadata attributes\n",
    "chip_promoter = chip_promoter_0.project(projected_meta=[\"EXP.epi__epigenome_id\", \"EXP.exp__mark\", \"EXP.manually_curated__format\"], new_attr_dict=None, projected_regs=[\"EXP.signal\",\"REF.attribute\"], new_field_dict=None)\n",
    "\n",
    "# materialize the results\n",
    "results = chip_promoter.materialize(raw_data_path+\"HG19_REMC_join_core_marks_all_tissues_dl0_1based\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-organize information and extract highest signal per Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of gmql output dir\n",
    "gmql_path = raw_data_path+\"HG19_REMC_join_core_marks_all_tissues\" + \"/files/\"\n",
    "gdm_list = list(set([i.split('.gdm', 1)[0] for i in os.listdir(gmql_path)]))\n",
    "\n",
    "# filter only samples starting with \"S_\"\n",
    "gdm_list_filtered = list(filter(re.compile(\".*S_\").match, gdm_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in gdm_list_filtered:\n",
    "    \n",
    "    # open .meta file\n",
    "    meta_file = pd.read_csv(gmql_path + sample + \".gdm.meta\", sep=\"\\t\", index_col=0, header=None).T\n",
    "    \n",
    "    cell_line = meta_file['EXP.epi__epigenome_id'][1] \n",
    "    if not os.path.exists(extracted_path + cell_line):\n",
    "        os.mkdir(extracted_path + cell_line)\n",
    "    \n",
    "    data_format = meta_file['EXP.manually_curated__format'][1] \n",
    "    if not os.path.exists(extracted_path + cell_line + \"/\" + data_format):\n",
    "        os.makedirs(extracted_path + cell_line + \"/\" + data_format)\n",
    "    \n",
    "    mark = meta_file['EXP.exp__mark'][1]\n",
    "    \n",
    "    # open .gdm file\n",
    "    gdm_file = pd.read_csv(gmql_path + sample + \".gdm\", sep = \"\\t\", names = [\"chr\", \"start\", \"stop\", \"strand\",\"score\", \"gene_name\"])\n",
    "    \n",
    "    # extract highest signal per gene\n",
    "    max_score = gdm_file.groupby(['gene_name'], as_index=False)['score'].max()\n",
    "    max_score.to_csv(extracted_path + cell_line + \"/\" + data_format + \"/\" + mark + \".txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data matrices for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(data_base_path+\"GeneFile.txt\", sep=\"\\t\", names = [\"seqname\", \"start\", \"end\", \"gene_name\"], usecols=[3])\n",
    "df_genes = pd.DataFrame(genes['gene_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_design_matrix(root_folder, cell_line, formats, histone_marks):\n",
    "    \n",
    "    genes = pd.read_csv(data_base_path+\"GeneFile.txt\", sep=\"\\t\", names = [\"seqname\", \"start\", \"end\", \"gene_name\"], usecols=[3])\n",
    "    df_genes = pd.DataFrame(genes['gene_name'])\n",
    "\n",
    "    cols = list()\n",
    "    for m, mark in enumerate(histone_marks):\n",
    "        path = root_folder + cell_line + \"/\" + formats[m] + \"/\" + mark + \".txt\"\n",
    "        df = pd.read_csv(path, sep=\"\\t\", header=0, dtype={'gene_name': str, 'score': np.float64}, usecols=[1,2])\n",
    "        df_all = df_genes.merge(df, how='left', on='gene_name', ).fillna(value=0.0)\n",
    "        col = df_all['score'].to_numpy().reshape(-1,1)\n",
    "        cols.append(col)\n",
    "    x = np.hstack(cols)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    '- broad': ['broadPeak', 'broadPeak', 'broadPeak', 'broadPeak', 'broadPeak'],\n",
    "    '- narrow': ['narrowPeak', 'narrowPeak', 'narrowPeak', 'narrowPeak', 'narrowPeak'],\n",
    "    '- gapped': ['gappedPeak', 'gappedPeak', 'gappedPeak', 'gappedPeak', 'gappedPeak'],\n",
    "    '- broad narrow': ['broadPeak', 'broadPeak', 'narrowPeak', 'narrowPeak', 'broadPeak'],\n",
    "    '- gapped broad': ['gappedPeak', 'gappedPeak', 'broadPeak', 'broadPeak', 'gappedPeak'],\n",
    "    '- gapped narrow': ['gappedPeak', 'gappedPeak', 'narrowPeak', 'narrowPeak', 'gappedPeak']}\n",
    "\n",
    "for conf in configurations:\n",
    "    print('\\n>> input configuration: ', conf)\n",
    "    for cell in cells:\n",
    "        print('\\r\\tcell: {}   '.format(cell), end='')\n",
    "        result_folder = '{}/{}/{}/'.format(data_base_path, conf, cell)\n",
    "        try:\n",
    "            os.makedirs(result_folder)\n",
    "        except OSError:\n",
    "            pass\n",
    "        x = generate_design_matrix(extracted_path, cell, configurations[conf], marks)\n",
    "        np.savetxt(result_folder+'X.csv', x, delimiter=',')\n",
    "        shutil.copy(data_base_path+'- targets/{}/T.csv'.format(cell), result_folder+'T.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
