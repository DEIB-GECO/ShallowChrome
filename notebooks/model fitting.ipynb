{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting: solving gene trascription state classification with _ShallowChrome_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model as lm\n",
    "import os\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths\n",
    "\n",
    "root_path = './../'\n",
    "\n",
    "# path to data, random splits, cell list\n",
    "data_base_path = root_path+'data/'\n",
    "split_base_path = data_base_path+'- splits/'\n",
    "cell_list_path = data_base_path+'cells.csv'\n",
    "\n",
    "# path to folder where to write results\n",
    "score_base_path = root_path+'scores/'\n",
    "try:\n",
    "    os.mkdir(score_base_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# suffixes\n",
    "data_suffix = ''\n",
    "split_suffix = 'iteration_'\n",
    "X_tail = 'X.csv'\n",
    "T_tail = 'T.csv'\n",
    "deepchrome_suffix = 'DeepChrome_scores.txt'\n",
    "\n",
    "# prepare list of data folders where to read\n",
    "# so to feed all the considered combinations\n",
    "# of input formats\n",
    "formats = ['- broad', '- broad narrow', '- gapped', '- gapped broad', '- gapped narrow', '- narrow']\n",
    "folders_by_format = list()\n",
    "for form in formats:\n",
    "    base = data_base_path + form + '/'\n",
    "    folders, cells = load_cell_paths(cell_list_path, base, suffix='/'+data_suffix)\n",
    "    folders_by_format.append(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set target epigenomes, model and fitting paramerters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will train and evaluate _ShallowChrome_ across all 56 epigenomes. Specific epigenomes of interest can be specified via variable `target_cells`. For example, one may just specify epigenomes `target_cells = ['E003', 'E123', 'E116']`, those for which pattern analyses are made in notebook `model inspection`.\n",
    "\n",
    "NB: l2-penalty coefficient `C = +∞` effectively enforces no penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target epigenome(s)\n",
    "\n",
    "# target_cells = ['E003', 'E123', 'E116']\n",
    "target_cells = cells\n",
    "cs = [np.where(cells==cell)[0][0] for cell in target_cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model and fitting parameters\n",
    "\n",
    "penalty='l2'\n",
    "C = + np.inf\n",
    "solver = 'lbfgs'\n",
    "max_iter = 6000\n",
    "multi_class = 'multinomial'\n",
    "random_state = 666\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train _ShallowChrome_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train, select and evaluate _ShallowChrome_ models for each target epigenome. In order to get some statistical confidence on model performance, the procedure is repeated `iterations` times; each time a different, randomly generated dataset split is employed. For reproducibilty we load already precomputed random splits; either way they can easily be regenerated from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training!\n",
    "    \n",
    "val_scores_by_cell = dict()\n",
    "test_scores_by_cell = dict()\n",
    "for c, cell in zip(cs, target_cells):\n",
    "    \n",
    "    # print advancement message\n",
    "    print '\\n\\n>> cell {0}...'.format(cell)\n",
    "\n",
    "    # set score folder(s)\n",
    "    score_folder = score_base_path+str(cell)\n",
    "    try:\n",
    "        os.mkdir(score_folder)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    # define score matrices\n",
    "    S_val = np.ndarray((len(formats), iterations))\n",
    "    S_test = np.ndarray((len(formats), iterations))\n",
    "\n",
    "    # loop for data formats\n",
    "    for f, form in enumerate(formats):\n",
    "\n",
    "        # print advancement message\n",
    "        print '\\r\\tformat: {0}        '.format(form),\n",
    "\n",
    "        # set score folder for format\n",
    "        score_folder_format = score_folder+'/'+form+'/'\n",
    "        try:\n",
    "            os.mkdir(score_folder_format)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "        # retrieve data\n",
    "        folder = folders_by_format[f][c]\n",
    "        X = np.loadtxt(folder+X_tail, delimiter=',')\n",
    "        T = binarize_target(np.loadtxt(folder+T_tail, delimiter=','))\n",
    "\n",
    "        # loop over random splits\n",
    "        for i in range(iterations): \n",
    "\n",
    "            # instantiate model\n",
    "            model = lm.LogisticRegression(penalty=penalty, C=C, random_state=random_state, solver=solver, max_iter=max_iter, multi_class=multi_class)\n",
    "            \n",
    "            # get split\n",
    "            split = load_split(split_base_path, split_suffix, i+1)\n",
    "\n",
    "            # fit model\n",
    "            cache_model_at = score_folder_format+'model_C_'+str(C)+'_iter_'+str(i+1)+'.pkl'\n",
    "            S_val[f,i], S_test[f,i] = fit_and_score(model, X, T, split, cache_model_at)\n",
    "\n",
    "    # save scores to disk\n",
    "    np.savetxt(score_folder+'/val_aucs.csv', S_val, delimiter=',', fmt='%.4f')\n",
    "    np.savetxt(score_folder+'/test_aucs.csv', S_test, delimiter=',', fmt='%.4f')\n",
    "    \n",
    "    # store them into dict\n",
    "    val_scores_by_cell[cell] = S_val\n",
    "    test_scores_by_cell[cell] = S_test\n",
    "    \n",
    "print ' done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_scores = dict()\n",
    "final_test_scores = dict()\n",
    "final_selection = dict()\n",
    "\n",
    "for cell in target_cells:\n",
    "    \n",
    "    S_val = val_scores_by_cell[cell]\n",
    "    S_test = test_scores_by_cell[cell]\n",
    "    final_val_scores[cell] = list()\n",
    "    final_test_scores[cell] = list()\n",
    "    final_selection[cell] = list()\n",
    "    for split in range(iterations):\n",
    "\n",
    "        val_scores = S_val[:, split]\n",
    "        test_scores = S_test[:, split]\n",
    "        best = np.argmax(val_scores)\n",
    "\n",
    "        final_val_scores[cell].append(val_scores[best])\n",
    "        final_test_scores[cell].append(test_scores[best])\n",
    "        final_selection[cell].append(formats[best])\n",
    "    \n",
    "    # print test performance\n",
    "    print '>> cell {0}: {1:.3f} ± {2:.3f} %'.format(cell, 100 * np.mean(final_test_scores[cell]), 100 * np.std(final_test_scores[cell]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  print aggregated stats\n",
    "\n",
    "data = [np.mean(final_test_scores[cell]) for cell in target_cells]\n",
    "data_std = [np.std(final_test_scores[cell]) for cell in target_cells]\n",
    "print 'mean:\\t{:.4f}'.format(np.mean(data))\n",
    "print 'median:\\t{:.4f}'.format(np.median(data))\n",
    "print 'max:\\t{:.4f}'.format(np.max(data))\n",
    "print 'min:\\t{:.4f}'.format(np.min(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dump all results\n",
    "\n",
    "shallowchrome_results_path = score_base_path+'ShallowChrome_scores.txt'\n",
    "with open(shallowchrome_results_path, 'w') as score_file:\n",
    "    for c, cell in enumerate(target_cells):\n",
    "        score_file.write(cell+': {0} +/- {1}\\n'.format(data[c], data_std[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare with other methods\n",
    "\n",
    "shallowchrome_results_path = score_base_path+'ShallowChrome_scores.txt'\n",
    "deepchrome_results_path = score_base_path+deepchrome_suffix\n",
    "deepchrome_scores = parse_scores(deepchrome_results_path, std=False)\n",
    "\n",
    "shallowchrome_scores = parse_scores(shallowchrome_results_path, std=True)\n",
    "if len(target_cells) < len(cells):\n",
    "    shallowchrome_scores_ = np.zeros((len(cells), 2))\n",
    "    for i, c in enumerate(cs):\n",
    "        shallowchrome_scores_[c] = shallowchrome_scores[i]\n",
    "    shallowchrome_scores = shallowchrome_scores_\n",
    "target_scores = [deepchrome_scores, shallowchrome_scores]\n",
    "sorter = np.argsort(-deepchrome_scores[:,0])\n",
    "\n",
    "w = 1.75\n",
    "s = 5\n",
    "y_labels_ = ['DeepChrome', 'ShallowChrome']\n",
    "name = \"Set2\"\n",
    "cmap = get_cmap(name)\n",
    "colors = cmap.colors\n",
    "\n",
    "fig = plt.figure(dpi=300, figsize=(10,6))\n",
    "for bb, b in enumerate(target_scores):\n",
    "    scores_mean = b[:,0]\n",
    "    if b.shape[-1] == 2:\n",
    "        std = b[:,1]\n",
    "    else:\n",
    "        std = np.asarray([0]*len(cells))\n",
    "    x = s*np.arange(len(cells)) + (w * (bb - 0))\n",
    "    plt.bar(x, scores_mean[sorter], width=w, yerr=std[sorter], align='center', ecolor='grey', capsize=0, color=colors[bb], label=y_labels_[bb])\n",
    "plt.yticks(np.arange(0.5, 1.0, 0.05), fontsize=11)\n",
    "plt.xticks(x, cells[sorter], fontsize=11, rotation=90)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.xlabel(\"epigenome\", fontsize=14)\n",
    "plt.ylabel(\"AUROC\", fontsize=12)\n",
    "plt.ylim([0.5, 0.93])\n",
    "plt.xlim([x[0]-2*w, x[-1]+w])\n",
    "fig.tight_layout()\n",
    "plt.savefig('./vsDeepChrome.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
